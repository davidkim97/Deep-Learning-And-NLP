# Chapter 06. 머신 러닝(Machine Learning) 개요

### 06-1 머신 러닝이란(What is Machine Learning?)

- 머신 러닝(Machine Learning)이 아닌 접근 방법의 한계

    - 머신러닝은 컴퓨터를 인간처럼 학습시킴으로써 인간의 도움 없이 컴퓨터가 스스로 새로운 규칙을 생성 할 수 있지 않을까 하는 발상으로 시작됨.

    - 기계 학습의 핵심은 표현(representation)과 일반화(generalization)에 있다.

    - 표현이란 데이터의 평가이며, 일반화란 아직 알 수 없는 데이터에 대한 처리이다.

- 머신 러닝 방식

    - 머신 러닝의 동작 방식은 
        ```
        1. 일정량 이상의 샘플 데이터를 입력
        2. 입력받은 데이터를 분석하여 일정한 패턴과 규칙을 찾아냄.
        3. 찾아낸 패턴과 규칙을 가지고 의사결정 및 예측 등을 수행.
        ```

---

### 06-2 머신 러닝 훑어보기

- 머신 러닝 모델의 평가

    - 기계를 학습하기 전 해당 데이터를 훈련용, 검증용, 테스트용 세 가지로 분리하는 것이 일반적.

    - 훈련 데이터는 머신 러닝 모델을 학습하는 용도.

    - 테스트 데이터는 학습한 머신 러닝 모델의 성능을 평가하기 위한 용도.

    - 검증용 데이터는 모델의 성능을 평가하기 위한 용도가 아니라 모델의 성능을 조정하기 위한 용도.

        - 모델이 훈련 데이터에 과적합(overfitting)이 되고 있는지 판단하거나 하이퍼파라미터의 조정을 위한 용도.

        - 하이퍼파라미터(초매개변수) : 모델의 성능에 영향을 주는 사람이 값을 지정하는 변수.

        - 매개변수 : 가중치와 편향. 학습을 하는 동안 값이 계속해서 변하는 수.

    - 가중치와 편향과 같은 매개변수는 사용자가 결정해주는 값이 아니라 모델이 학습하는 과정에서 얻어지는 값이다.

    - 훈련용 데이터로 훈련을 모두 시킨 모델은 검증용 데이터를 사용하여 정확도를 검증하며 하이퍼파라미터를 튜닝(tuning)한다.

    - 튜닝하는 과정에서 모델은 검증용 데이터의 정확도를 높이는 방향으로 점차적으로 수정됨.

    - 튜닝 과정을 모두 끝내고 모델의 최종 평가를 하고자 한다면, 검증용 데이터로 모델을 평가하는 것은 적합하지 않다.

- 분류(Classification)와 회귀(Regression)

    - 이진 분류 문제(Binary Classification)
        - 주어진 입력에 대해서 두 개의 선택지 중 하나의 답을 선택해야 하는 경우를 말한다.  
        -> ex) 메일을 보고 스팸 메일인지 정상 메일인지 판단하는 문제가 속한다.

    - 다중 클래스 분류(Multi-class Classification)
        - 주어진 입력에 대해서 세 개 이상의 선택지 중에서 답을 선택해야 하는 경우를 말한다.

    - 회귀 문제(Regression)
        
        - 분류 문제처럼 둘 중 하나를 선택해야 한다거나, 어떠한 연속적인 값의 범위 내에서 예측값이 나오는 경우를 말한다.

        - 회귀 문제의 예시로 시계열 데이터(Time Series Data)를 이용한 주가 예측, 생산량 예측, 지수 예측 등이 있다.

- 지도 학습과 비지도 학습

    - 지도 학습(Supervised Learning)

        - 지도 학습이란 레이블(Label)이라는 정답과 함께 학습하는 것을 말한다.

        - 자연어 처리는 대부분 지도 학습에 속한다.

    - 비지도 학습(unsupervised Learning)

        - 비지도 학습은 데이터에 별도의 레이블이 없이 학습하는 것을 말한다.

        - 예를 들어 텍스트 처리 분야의 토픽 모델링 알고리즘인 LSA나 LDA는 비지도 학습에 속한다.

    - 자기지도 학습(Self-Supervised Learning, SSL)

        - 레이블이 없는 데이터가 주어지면, 모델이 학습을 위해서 스스로 데이터로부터 레이블을 만들어서 학습하는 경우를 자기지도 학습이라고 한다.

        - 대표적인 예시로 Word2Vec과 같은 워드 임베딩 알고리즘이나, BERT와 같은 언어 모델의 학습 방법을 들 수 있다.

- 샘플(Sample)과 특성(Feature)

    - 머신 러닝에서는 하나의 데이터, 행렬 관점에서는 하나의 행을 샘플(Sample)이라고 부른다.  
    -> DB에서 레코드라 부르는 단위

    - 각 종속 변수를 예측하기 위한 각각의 독립 변수를 특성(Feature)이라고 부른다.  
    -> 행렬 관점에서는 각 열에 해당

- 혼동 행렬(Confusion Matrix)

    - 머신 러닝에서는 맞춘 문제수를 전체 문제수로 나눈 값을 정확도(Accuracy)라고 한다.

    - 정확도는 맞춘 결과와 틀린 결과에 대해 세부적인 내용을 알려주지 않는다.  
    이를 위해 사용하는 것이 혼동 행렬(Confusion Matrix)이다.

    - 혼동 행렬에서 각 열은 예측값을 나타내며, 각 행은 실제값을 나타낸다.

        ||예측 참|예측거짓|
        |---|---|---|
        |실제 참| TP|FN|
        |실제 거짓| FP|TN|

    - True Positive(TP) : 실제 True인 정답을 True라고 예측 (정답)
    - False Positive(FP) : 실제 False인 정답을 True라고 예측 (오답)
    - False Negative(FN) : 실제 True인 정답을 False라고 예측 (오답)
    - True Negative(TN) : 실제 False인 정답을 False라고 예측 (정답)

    - 이 개념을 사용하면 정밀도(Precision)과 재현율(Recall)이 된다.

    - 정밀도(Precision)
        - 정밀도란 모델이 True라고 분류한 것 중에서 실제 True인 것의 비율

    - 재현율(Recall)
        - 재현율이란 실제 True인 것 중에서 모델이 True라고 예측한 것의 비율
        - Precision이나 Recall은 모두 실제 True인 정답을 모델이 True라고 예측한 경우.  
        즉, TP에 관심이 있다.

    - 정확도(Accuracy)
        - 정확도(Accuracy)는 우리가 일반적으로 실행활에서도 가장 많이 사용하는 지표이다.
        - 전체 예측한 데이터 중에서 정답을 맞춘 것에 대한 비율이다.
        - 이렇게 실질적으로 더 중요한 경우에 대한 데이터가 전체 데이터에서 너무 적은 비율을 차지한다면 정확도는 좋은 측정 지표가 될 수 었다.

- 과적합(Overfitting)과 과소 적합(Underfitting)

    - 과적합(Overfitting)은 학습데이터를 과하게 잘 학습하는 것을 뜻한다.

    - 과적합 상황에서는 훈련 데이터에 대해서 오차가 낮지만, 테스트 데이터에 대해서는 오차가 커진다.

    - 반면, 테스트 데이터의 성능이 올라갈 여지가 있음에도 훈련을 덜 한 상태를 과소적합(Underfitting)이라고 한다.

    - 과소 적합은 훈련 자체가 부족한 상태이므로 훈련 횟수인 에포크가 지나치게 적으면 발생할 수 있다.

    - 과소 적합은 훈련 자체를 너무 적게한 상태이므로 훈련 데이터에 대해서도 정확도가 낮다는 특징이 있음.

---

### 06-3 선형 회귀(Linear Regression)

- 선형 회귀(Linear Regression)

    - 머신 러닝의 가장 큰 목적은 실제 데이터를 바탕으로 모델을 생성해서 만약 다른 입력 값을 넣었을 때 발생할 아웃풋을 예측하는 것에 있다.

    - 찾아낼 수 있는 가장 직관적이고 간단한 모델은 선(line)이다.  
    그래서 데이터를 놓고 그걸 가장 잘 설명할 수 있는 선을 찾아 분석하는 방법을 선형회귀(Linear Regression)분석이라 한다.

    - 종속변수 Y와 한 개 이상의 독립변수 X와의 선형 상관관계를 모델링하는 회귀분석 기법이다.

    - 단순 선형 회귀 분석(Simple Linear Regression Analysis)

    - 다중 선형 회귀 분석(Multiple Linear Regression Analysis)

- 선형 회귀에서 발생하는 오차, 손실(Loss)
    - 선은 실제 데이터와 약간의 차이가 발생한다. 일종의 오차라 할 수 있는데, 이를 손실(Loss)라 한다.

    - 선과 실제 데이터 사이에 얼마나 오차가 있는지 구하려면 양수, 음수 관계 없이 동일하게 반영되도록 모든 손실에 제곱을 해주는 것이 좋다.

        - 이 방식으로 손실을 구하는 것을 평균 제곱 오차(mean squared error, MSE)라고 한다.

        - 손실을 구할 때 가장 널리 쓰이는 방법이다.

- <span style='font-weight:bold; color:tomato'>선형 회귀 모델의 목표는 모든 데이터로부터 나타나는 오차의 평균을 최소화할 수 있는 최적의 기울기와 절편을 찾는 것이다.

- 손실을 최소화 하기 위한 방법, 경사하강법(Gradient Descent)

    